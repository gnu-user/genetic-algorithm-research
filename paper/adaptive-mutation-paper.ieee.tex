
\documentclass[conference]{IEEEtran}
\usepackage{stmaryrd}
\usepackage{amsfonts}
% If the IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it: e.g.,
% \documentclass[conference]{../sty/IEEEtran}

\usepackage{graphicx,times,amsmath} % Add all your packages here
\usepackage{epstopdf}
\usepackage{algorithm2e}
\usepackage{multirow}
\usepackage[hidelinks]{hyperref}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor IEEEtran}

\IEEEoverridecommandlockouts    % to create the author's affliation portion
                % using \thanks

\textwidth 178mm    % <------ These are the adjustments we made 10/18/2005
\textheight 239mm   % You may or may not need to adjust these numbers again
\oddsidemargin -7mm
\evensidemargin -7mm
\topmargin -6mm
\columnsep 5mm

\begin{document}


% paper title: Must keep \ \\ \LARGE\bf in it to leave enough margin.
\title{\ \\ \LARGE\bf Genetic Algorithm with Self-Adaptive Mutation Controlled by Chromosome Similarity\thanks{Daniel Smullen, Jonathan Gillett, Joseph Heron, and Shahryar Rahnamayan are with The Faculty of Engineering and Applied Science at the University of Ontario Institute of Technology, Oshawa, Ontario, Canada (email: \{daniel.smullen, jonathan.gillett, joseph.heron\}@uoit.net, shahryar.rahnamayan@uoit.ca).} \thanks{We would like to thank the SHARCNET organization for graciously providing the high performance computing facilities we needed to run our experiments.}}

\author{Daniel Smullen, Jonathan Gillett, Joseph Heron, Shahryar Rahnamayan}

% avoiding spaces at the end of the author lines is not a problem with
% conference papers because we don't use \thanks or \IEEEmembership
% use only for invited papers
%\specialpapernotice{(Invited Paper)}

% make the title area
\maketitle

\begin{abstract}
Proposed is a novel methodology for combinatorial optimization using self-adaptive mutation probabilities in genetic algorithms (GA). We selected the N-Queen problems ($8 \leq N \leq 32$) as our benchmark, as they are multi-modal with many local and global optima. Optimal static mutation probabilities for the traditional GA approach were determined for each $N$ to use as a best-case scenario benchmark in comparative analysis. Despite an unfair advantage with traditional GA using optimized fixed mutation probabilities, in large problem sizes (where $N > 14$) multi-objective analysis showed the self-adaptive approach yielded a 100.67\% to 584.02\% improvement in the number of distinct solutions generated; the self-adaptive approach also produced the first distinct solution faster than traditional GA.
\end{abstract}

% no key words

\section{Introduction}
\PARstart{G}{enetic algorithms} (GA) are particularly useful in areas which they can perform stochastic generation of solutions for complex or large combinatorial problems \cite{1,2}. One well-known problem area includes the N-Queen problems. An efficient and common approach to tackle these problems uses genetic algorithms, encoding positions of the N-Queens on the chessboard into the chromosome. As with any genetic algorithm, evaluating the fitness of the chromosomes is required to determine the quality of candidate solutions \cite{8}, but the N-Queen problems are different in that only those candidates with perfect fitness are considered correct solutions to the problem. 

Tuning up control parameters has a crucial effect on the GA's performance, which can increase or decrease based on the landscape and size of the problem encountered \cite{12,13,15,7}. We have found that by replacing the traditional GA's static mutation probability with a self-adaptive variable mutation probability, better performance can be achieved when solving the N-Queen problems from both a single and multi-objective perspective. Our objectives focus on generating the most solutions possible within a fixed budget, and/or generating the first solution as quickly as possible. The new approach adapts based on the similarity of chromosomes in the population each generation. The increase in performance is compounded in larger versions of the problem where the search space grows extremely large, such as the situation encountered when attempting to solve higher-order N-Queen problems. In this domain, deterministic methods prove useless but our approach prevails.

Our software solution was written in Java, and is available through GitHub at the following URL: \texttt{http://git.io/RKfAvQ}. It is open source licensed under the \textit{GNU General Public License, Version 3}.

\section{Background}
The N-Queen problems are multi-modal, with many local optima and global optima. 
Like many other complex optimization problems, the N-Queen problems become staggeringly complex as the problem size increases \cite{3}. The problem is defined by the rules of chess and the protective embedded constraints of the chromosome which prevent queens from sharing rows or columns; when two queens share the same diagonal, a collision occurs, meaning that the board state is not a solution. A solution is found when all solutions have been found in which no queens on the board can attack another. This problem is {$O(n!)$} when approached using deterministic methods to find all possible solutions. 


% TABLE - N QUEENS PROBLEM GROWTH
\begin{table}[h!]\label{table:probgrowth}
\centering
\caption{N-Queen Problems Distinct Solutions}
\begin{tabular}{|l|l|l|} \hline
$N$  & Problem Size ($N!$)      & Distinct Solutions     \\ \hline
8  & 40320                      & 92                     \\
9  & 362880                     & 352                    \\
10 & 3628800                    & 724                    \\
11 & 39916800                   & 2680                   \\
12 & 479001600                  & 14,200                 \\
13 & 6227020800                 & 73,712                 \\
14 & 87178291200                & 365,596                \\
15 & $1.307674368\times10^{12}$ & 2,279,184              \\
16 & $2.092278989\times10^{13}$ & 14,772,512             \\
17 & $3.556874281\times10^{14}$ & 95,815,104             \\
18 & $6.402373706\times10^{15}$ & 666,090,624            \\
19 & $1.216451004\times10^{17}$ & 4,968,057,848          \\
20 & $2.432902008\times10^{18}$ & 39,029,188,884         \\
21 & $5.109094217\times10^{19}$ & 314,666,222,712        \\
22 & $1.124000728\times10^{21}$ & 2,691,008,701,644      \\
23 & $2.585201674\times10^{22}$ & 24,233,937,684,440     \\
24 & $6.204484017\times10^{23}$ & 227,514,171,973,736    \\
25 & $1.551121004\times10^{25}$ & 2,207,893,435,808,352  \\
26 & $4.032914611\times10^{26}$ & 22,317,699,616,364,044 \\
\dots & \dots & Unknown				\\
\hline\end{tabular}
\label{table:numuniquesol}
\end{table}

Table \ref{table:probgrowth} shows the massive increase in problem size as $N$ increases. Further, it shows the proportionally huge increase in the number of distinct solutions. Based on the scale of the problem at higher values of $N$, using deterministic methods is futile - the problem is simply too big. As $N$ increases past 26, the problem becomes completely intractable. The number of distinct solutions for large values of $N$ is unknown, and the problem size becomes enormous. 

% FIGURE - HISTOGRAM
\begin{figure}[h!]\label{fig:histogram}
\centering
\includegraphics[width=0.45\textwidth]{8_queens_histogram.png}
\vspace{-12pt}
\caption{8-Queens Collisions Histogram}
\label{fig:histogram}
\end{figure}

8-Queen is the classical version of N-Queen. The histogram found in Figure \ref{fig:histogram} shows the full deterministic traversal of the 8-Queen problem landscape, which is characteristic of the N-Queen problems. It details the myriad possibilities for the number of board states which can occur even in a relatively small problem size. Not pictured in this figure are the 4 instances of 44 simultaneous collisions, and 2 instances of 56 collisions. These occur when 7, or all 8 queens are all placed on the diagonals, respectively. 

While finding the most solutions given a fixed number of function calls/generations was the main objective of our proposed approach, fundamentally there are two separate objectives in tackling N-Queen problems; finding the first solution as fast as possible is an alternative goal. The latter problem can be solved in polynomial time through conventional means.

\section{Related Work}
Deterministic attempts to solve N-Queen problems have been successful only for values of $N$ up to 26 \cite{20}, and attempts to find single solutions quickly have been made for versions of the problem up to {$N = 50$} \cite{21}. There are no known integer sequences or proofs which can represent the number of distinct solutions for $N > 26$, nor is there a deterministic means which can find them all within human time frames, but traditional GA have been used to find multitudinous solutions within fixed time frames \cite{9,10}. This approach is repeated in our experiments.

Since tuning control parameters has a profound effect on the evaluation of GA, one might conclude that there is an optimal static mutation probability \cite{4} for solving N-Queen problems using the traditional approach. Hesser and M\"{a}nner \cite{14} attempted to find such a value for GA in general problems but failed - there is no perfect algorithm, and it is rare that there is an optimal control parameter for a very good algorithm which fits all circumstances. This is an important axiom of the No Free Lunch (NFL) theorem \cite{6}. Finding the pragmatic best case scenario for static $M_{c}$ within traditional GA proved to be a useful control and benchmark for our experiments, as can be seen in our results.

Other alternative approaches to enhancing GA for combinatorial optimization sought to increase population diversity in order to overcome wasteful convergence on local optima, which is problematic in N-Queen since it has many local and global optima. Combining standard GA with randomly generated individuals into the population is well studied \cite{12}, but fails to adapt to suit the problem size. Still, exploring the nature of genetic diversity provides valuable insight into the motivation for increasing diversity among candidate solutions and populations to reach better solutions within smaller budgets.

Adaptive GA have historically manipulated control parameters by changing the mutation probability over time \cite{12} such that it is low during exploration, high during exploitation, or vice-versa. Other approaches used the overall mean population fitness to adjust genetic operators independently of time \cite{11,15,7}. Alternative adaptive approaches changed mutation probabilities between two values based on fitness \cite{15}, while others attempted to individually specify genetic operator probabilities into each phenotype, encoded with meta-operators that govern their evaluation \cite{5}. Many previous adaptive approaches sought to yield more fruitful explorations of the problem landscape by tuning GA control parameters, but most approaches have been limited by being na\"{i}ve to either the problem size or the state of exploration and diversity. However, these historical adaptive methodologies yield many advantages over traditional GA in that they preclude the need for \textit{a priori} knowledge about optimal control parameters, mitigating the need to 'tune them up' with protracted test runs prior to long-term evaluation, which saves time.

\section{Proposed Approach}\label{params}
Our main motivation for this new self-adaptive approach was to leverage the observed tendency in nature for mutations to occur as a result of inbreeding with genetically similar specimens \cite{17,18}. Our desire was to replicate this behavior in GA. We noted that mutations that resulted from inbreeding increased genetic diversity in biological organisms, affecting their fitness in nature sometimes for better or for worse. Therefore, it stood to reason that a similar phenomenon might occur in GA. Exploring this idea yielded surprisingly positive results.

We used a GA with an integer encoded chromosome to represent the N-Queen positions on the chessboard. By limiting queens to single rows and columns, our approach includes protective embedded constraints which reduce the dimensionality of the problem. It uses traditional GA operators - selection, mutation, and recombination. Ordinary roulette wheel selection \cite{19} is used in conjunction with single-value uniform mutation and single-point crossover/recombination \cite{16}. 

Chromosome similarity is used as the defining characteristic of our adaptation approach. The probability for the mutation operator is variable, while recombination ($P_{crossover}$) remains at a single static value as in traditional GA. The mutation operator probability delta (per 1 generation) is set to a fixed value. Our experimental values for the genetic operators are seen in Table \ref{table:geneticoperators}.

%PUT IN THE TABLE FOR THE COSNTANTS HERE, REFERENCE IS HERE ^^^^

\subsection{Self-Adaptive Mutation}
In order to apply our self-adaptive mutation approach, a two step process is required. First, for each generation of chromosomes the population's chromosome similarity must be evaluated. The similarity algorithm is detailed in Algorithm \ref{alg:similarity}. Next, the mutation probability is varied accordingly in order to adapt.  

When the chromosome similarity is less than the specified threshold ($S_{t}$), the population is too dissimilar. This means the mutation probability must decrease, because the population is not inbred. For the next generation, the mutation probability is subtracted by the fixed delta value seen in Table \ref{table:geneticoperators}. After application of genetic operations and selection on the population, the next generation is populated and their chromosome similarity is calculated. If the chromosome similarity has increased, and if it is ever above the specified threshold, the population is inbred. $M_{a}$ must increase by the fixed delta in the next generation to adapt.

Variations in chromosome similarity may result independently of the applied uniform mutation operator. Since the recombination probability ($P_{crossover}$) is 70\%, the recombinant permutations are likely to be approximately 30\% similar (due to cloning) unless uniform mutation has occurred on the cloned genes. Our experimentally observed result using adaptive mutation is that the chromosome similarity will approach an equilibrium percentage approximately equal to the specified similarity threshold as generations evolve.

\subsection{Chromosome Similarity Algorithm}
Chromosome similarity is calculated using a greedy algorithm, seen in Algorithm \ref{alg:similarity}. First, the chromosomes' genes are decoded and re-encoded into integer values and concatenated into one large integer. Next, the resultant array of integer representations is sorted. Our implementation uses the quick-sort algorithm provided by Java for minimal computational overhead. This gives the similarity algorithm its' characteristic asymptotic behavior, as the complexity of the sorting function itself is of higher complexity than the rest of the main similarity calculation algorithm. Quick-sort runs on average in $O(n \log n)$ complexity, although it should be noted that in the theoretical worst case, quick-sort works in $O(n^2)$ which is highly unlikely. The main algorithm runs in $O(n)$ linear complexity independent of the sorting. Similar chromosomes have the same genes. A population with 100\% similarity is completely identical.

\begin{algorithm}
  \SetKwProg{Fn}{Function}{}{end}\SetKwFunction{Similarity}{Similarity}%
  \SetKwData{Similar}{similar}\SetKwData{Value}{value}\SetKwData{Matched}{matched}\SetKwData{Length}{length}\SetKwArray{Sorted}{sorted}
  \SetKwFunction{Sort}{Sort}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetAlgoLined
  \DontPrintSemicolon
  
  \Fn{\Similarity{$chromosomes$}}{
  
  \Input{An array of $chromosomes$}
  \Output{Fraction of chromosomes that are similar}
  \BlankLine
  
  \Similar $\leftarrow$ 0\;
  \Matched $\leftarrow$ false\;
  \Length $\leftarrow$ length of $chromosomes$\;
  \BlankLine
  
  \tcp{Sort using an arbitrary sorting algorithm}
  \Sorted $\leftarrow$ \Sort{$chromosomes$}\;
  \BlankLine
  
  \For{$i \leftarrow 0$ \KwTo $\Length -1$}
  {
    \uIf{\Sorted{$i$} == \Sorted{$i + 1$}}
    {
      \Similar $\leftarrow$ \Similar + 1\;
      \Matched $\leftarrow$ true\;
    }
    \ElseIf{\Matched}
    {
      \Similar $\leftarrow$ \Similar + 1\;
      \Matched $\leftarrow$ false\;
    }
    \BlankLine
    
    \tcp{Case where the last item is a match}
    \If{\Matched and $\left(i + 1 == \Length - 1 \right)$}
    {
      \Similar $\leftarrow$ \Similar + 1\;
    }
  }
  \BlankLine
  \KwRet{\Similar / \Length}
  }
\caption{Chromosome similarity function}
\label{alg:similarity}
\end{algorithm}

\subsection{Fitness Function}
Candidate solution fitness is evaluated by determining the number of collisions between queens on the chessboard. This means that in a board state where one queen can attack another, two collisions result. The algorithm for determining the fitness of a given board state is given in Algorithm \ref{alg:fitness}, showing the mechanisms used to find collisions across diagonals on the board. The overall board state fitness is calculated as $fitness = \frac{1}{C}$, where $fitness = 1$ if $C = 0$. The number of collisions is $C$. Maximum fitness is achieved when $C = 0$ as there are no collisions, resulting in a distinct board solution. For example, in the classical 8-Queen problem, the ideal fitness is 1, and the worst case fitness is $1/56$.
 
\begin{algorithm}[t!]
  \SetKwProg{Fn}{Function}{}{end}\SetKwFunction{Fitness}{Fitness}%
  \SetKwData{Collisions}{collisions}\SetKwData{Length}{length}\SetKwArray{Chromosome}{$chromosome$}\SetKwData{Yi}{$y_i$}\SetKwData{Yj}{$y_j$}
  \SetKwFunction{Abs}{abs}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetAlgoLined
  \DontPrintSemicolon
  
  \Fn{\Fitness{$chromosome$}}
  {
    \Input{A single $chromosome$}
    \Output{A fitness value for the chromosome}
    \BlankLine
    
    \Collisions $\leftarrow$ 0\;
    \Length $\leftarrow$ length of the $chromosome$\;
    \BlankLine
    
    \For{$i \leftarrow 0$ \KwTo $\Length -1$}
    {
      \tcp{Check each gene against the current}
      $j \leftarrow \left( i + 1 \right) \mod{\Length}$\;
      \While{$j$ != $i$}
      {
        \Yi $\leftarrow \Chromosome{i}$\;
        \Yj $\leftarrow \Chromosome{j}$\;
        \BlankLine
        
        \tcp{Check for vertical collision}
        \If{\Yi == \Yj}
        {
          \Collisions $\leftarrow \Collisions + 1$\; 
        }
        \BlankLine
        
        \tcp{Check for diagonal collision}
        \If{\Abs{$\left(i - j \right)$ / $\left(\Yi - \Yj \right)$} == 1}
        {
          \Collisions $\leftarrow \Collisions + 1$\;
        }
        \BlankLine
        
        $j \leftarrow j + 1$\;
        $j \leftarrow j \mod{\Length}$\;
      }
    }
    \BlankLine

    \eIf{\Collisions == 0}
    {
      \KwRet{1}\;
    }
    {
      \KwRet{1 / \Collisions}\;
    }
  }
\caption{Fitness function}
\label{alg:fitness}
\end{algorithm}

\subsection{Identifying Distinct Solutions}
Each generation, there is a likelihood that some of the chromosomes in the current population are valid solutions - any of the current generation's chromosomes with a fitness of 1 is some sort of solution. Whether it is distinct or not is unknown at first. When a solution is found, it must be compared to the list of previously found solutions. Each generation, there is always a strong possibility that many candidate solutions are duplicates of previously found solutions. Symmetry operations are applied to each solution found to generate more distinct solutions based on the symmetrical nature of the chessboard. This may further increase the likelihood that the new population's solutions have already been found previously. Therefore, indistinct solutions are discarded without having symmetry operations applied as their reconfiguration would already be identical to symmetric configurations of previously found distinct solutions. After saving newly found solutions, the new generation replaces the previous generation and the GA continues.

Symmetry operations consist of three $90^{\circ}$ rotations, a horizontal reflection, and then 3 further $90^{\circ}$ rotations of the reflected board. Each symmetrical board configuration is a candidate solution that is checked against the existing distinct solution, and discarded if it has already been found previously. Each distinct solution can potentially yield 8 more distinct solutions depending on the placement of queens.

\section{Experimental Methodology}
We measured the performance of our self-adaptive approach using an empirical study. Our methodology was to solve N-Queen problems for various values of N with a limited budget of function calls (generations), repeated a multitude of times to ensure accuracy and collect aggregate statistics. Table \ref{table:trials} shows the number of function calls permitted and the number of trials run for each value of N. Special budgets and trial multiplicities were set for $N = 32$ in order to accommodate the exceptionally large problem size.

Our control used traditional GA with fixed mutation probabilities ($M_{c}$) of $M_{c}$ = 1\%, 5\%, 10\%, 15\%, 20\%, 25\%, 30\%, 35\%, 40\%, 45\%, 50\%, 55\%, 60\%, 65\%, 70\%, 75\%, 80\%, 85\%, 90\%, 95\% and 100\% to solve each N-Queen problem. These trials were run with the same multiplicity and budget as our self-adaptive approach. The goal of the control trials was to approximately determine the optimal $M_{c}$ for finding the most solutions for each problem given the budget, and finding the first solution in as few generations as possible. Our aim was to test our new approach against a reasonable approximation of the best possible performance that the traditional GA approach can provide. Optimized control parameters for mutation would be determined and used as a benchmark, similar to Hesser and M\"{a}nner's study.


% TABLE - EXPERIMENTAL VARIABLES
% TODO HAVE SHAHRYAR LOOK OVER THE VARIABLES/NAMING USED
\begin{table}\label{table:geneticoperators}
\centering
\caption{Experimental Control Parameters}
\begin{tabular}{|l|l|} \hline
Variable&                                     Value \\ \hline
Similarity Threshold ($S_{t}$)&               $15\%$ \\ \hline
Adaptive Mutation Bounds ($M_{a}$)&           $[1, 99]$ \\ \hline   
Adaptive Mutation Increment ($M_{a\Delta}$)&  $1$ \\ \hline
Crossover Probability ($P_{crossover}$)&      $70\%$ \\ \hline
Cloning Probability ($P_{cloning}$)&          $30\%$ \\ \hline
Population Size ($P$)&                        $64$ \\ \hline      
\end{tabular}
\label{table:variables}
\end{table}


% TABLE - EXPERIMENTAL TRIALS/TESTS
% TODO HAVE SHAHRYAR LOOK OVER THE VARIABLES/NAMING USED
\begin{table}\label{table:trials}
\centering
\caption{Experimental Trials}
\begin{tabular}{|l|l|l|} \hline
$N$&        Function Call Cutoff ($F_{cutoff}$)&     Trials \\ \hline
8&          10,000,000&         30 \\ \hline
9&          10,000,000&         30 \\ \hline
10&         10,000,000&         30 \\ \hline
11&         10,000,000&         30 \\ \hline
12&         10,000,000&         30 \\ \hline
13&         10,000,000&         30 \\ \hline
14&         10,000,000&         30 \\ \hline
15&         10,000,000&         30 \\ \hline
16&         10,000,000&         30 \\ \hline
18&         10,000,000&         15 \\ \hline
20&         10,000,000&         15 \\ \hline
22&         10,000,000&         15 \\ \hline
24&         10,000,000&         15 \\ \hline
26&         10,000,000&         15 \\ \hline
32&         50,000,000&         10 \\ \hline
\end{tabular}
\label{table:trials}
\end{table}

For $N = 8$ through 16, 30 tests were performed at each $M_{c}$ ($21 \times 30 = 630$ tests total), and 30 runs were performed using the self-adaptive approach. For $N = 18$ through 26, 15 tests were performed. For $N = 32$, 10 tests were performed. Given the increasingly large problem sizes, the number of tests were reduced in order to allow experimentation to complete within reasonable human time frames. Descriptive statistics were gathered every 1000 generations, with mean calculated using the grand mean.

\section{Results and Analysis}
The performance difference with respect to solutions generated can be seen in Table \ref{table:distinctsol}. As can be seen in the table, the traditional GA approach performs marginally better in the range of small problems, most of which are most efficiently solved with deterministic methods. This range consists of values of $N$ up until $N = 14$. Our self-adaptive approach yields more solutions for values of $N$ where $N > 14$. As $N$ increases, the difference widens; the self-adaptive approach provides increasingly better results for this objective as the problem size increases.

We observed that there was a proportional inverse relationship between $N$ and the best experimentally determined $M_{c}$. As $N$ increases, the best $M_{c}$ which yielded the most solutions decreases. The point this raises is that there is an unfair advantage for the traditional GA over the self-adaptive approach, since the optimal static $M_{c}$ changes as $N$ changes. Nobody knows the ideal $M_{c}$ for all problems, and generally foreknowledge of the ideal $M_{c}$ is not available in order to exploit this advantage \cite{14} but in this case it was experimentally determined for this problem. Optimally tuned control parameters are critical and provide a major advantage. Still, the self-adaptive approach consistently outperforms traditional GA with optimized parameters for the large problem sizes, even as the parameters are adjusted to suit the problem better. Our conclusion is that the self-adaptive approach will continue to outperform the traditional GA method as $N$ grows based on the increasing gap in performance.

Our analysis of the algorithm shows that the self-adaptive approach adjusts the mutation probability throughout the duration of the solution search. Unlike other historical approaches to adaptation, the self-adaptive one does not adapt purely based on one characteristic of the problem, the position of the problem landscape traversal, or fitness values. Our results also show that adaptation occurs every generation since stochastic factors routinely influence the similarity beyond or below $S_{t}$. This behavior can be seen in Figure \ref{fig:sim32q}, which shows that the similarity adapts towards the specified $S_{t}$.


\begin{figure}[htp]\label{fig:sim32q}
\centerline{\includegraphics[width=3.4in]{similarity_variable_32q.png}} \caption{Chromosome Similarity vs Generations for the 32-Queen Problem (Self-Adaptive)} 
\end{figure}

%%PUT IN A FIGURE HERE WHICH SHOWS THE SIMILARITY ADAPTING TOWARD THE SPECIFIED THRESHOLD

When controlled by the chromosome similarity, the self-adaptive approach increases diversity and generates more solutions through a more diverse and efficient traversal of the areas of the problem landscape that contain solutions. The reason why the diversity is increased is because the search is prevented from regenerating chromosomes which are identical, flooding the population with clones. By definition a diverse population cannot be identical. Controlling similarity allows the self-adaptive approach to strike a balance between convergence, exploitation, and exploitation. Therefore, there is a relationship between diversity and chromosome similarity which enables the diversity of the population to be controlled by the chromosome similarity threshold specified. In traditional GA, when the chromosome similarity is too high, diversity is low and few solutions are found. This is evident by the poor performance yielded by traditional GA in our benchmarks where $M_{c}$ is very small. There is no mechanism other than the constant background mutation that increases diversity among the population, since recombination of identical chromosomes results in a clone regardless. Conversely, when mutation is too frequent (such as in high values of $M_{c}$ like 100\%), similarity becomes low, and the diversity of the population becomes too high to allow optima to be converged upon. In the self-adaptive approach, when solutions are converged upon, diversity increases as the mutation rate adapts in order to expand the search to other solutions. This behavior is the desirable characteristic of the self-adaptive approach that makes it ideal for multi-modal problems with many optima like N-Queen problems. Controlled similarity prevents the GA from being stuck in a rut of similar local optima, while also preventing the search from being wildly dissimilar and random, failing to converge on optima.

\subsection{Multi-Objective Optimization}
While our primary goal was to compare which approach generated as many solutions as possible on a fixed budget, the secondary aim of the N-Queen problems was to generate a single solution as quickly as possible. This can theoretically be performed in polynomial time using deterministic methods, but when the problem size is very large this is nowhere near as fast or efficient as stochastic approaches.

Our results for multi-objective optimization (seen in Table \ref{table:firstsol}) toward the N-Queen problems show that we were able to generate a solution first in 8 out of 15 instances, in problems where $N > 14$. The conclusion is that even in multi-objective optimization our self-adaptive approach prevails in spite of the NFL theorem.

\begin{table}\label{table:distinctsol}
\centering
\caption{Most N-Queens Distinct Solutions}
\begin{tabular}{|l|l|l|l|l|} \hline
&               &  \multicolumn{2}{c|}{Distinct Solutions}& \\ \cline{3-4}
$N$&  Best $M_{c}$&  Best $M_{c}$&    Self-Adaptive ($M_{a}$)&    Difference\\ \hline
8&  0.95&          92&              92&                         $\pm$ 0\% \\ \hline                        
9&  0.95&          352&             352&                        $\pm$ 0\% \\ \hline
10& 0.9&           724&             724&                        $\pm$ 0\% \\ \hline
11& 0.85&          2,680&           2,680&                      $\pm$ 0\% \\ \hline
12& 0.85&          13,690&          11,986&                     $-$12.45\% \\ \hline
13& 0.8&           32,128&          26,308&                     $-$18.12\% \\ \hline
14& 0.8&           41,520&          29,520&                     $-$28.90\% \\ \hline
15& 0.8&           30,356&          30,324&                     $+$0.11\% \\ \hline
16& 0.8&           15,016&          30,132&                     $+$100.67\% \\ \hline
18& 0.75&          16,392&          27,120&                     $+$65.45\% \\ \hline
20& 0.75&          7,872&           25,608&                     $+$225.30\% \\ \hline
22& 0.7&           6,008&           25,376&                     $+$322.37\% \\ \hline
24& 0.7&           6,440&           24,560&                     $+$281.37\% \\ \hline
26& 0.7&           6,280&           23,008&                     $+$266.37\% \\ \hline
32& 0.65&          15,216&          104,080&                    $+$584.02\% \\ \hline
\end{tabular}
\label{table:mostsol}
\end{table}

\begin{table}\label{table:firstsol}
\centering
\caption{First N-Queens Distinct Solution}
\begin{tabular}{|l|l|l|l|l|} \hline
$N$&    Fastest $M_{c}$&    $\mu$ Gens. $M_{c}$&    $\mu$ Gens. $M_{a}$&    Difference\\ \hline
 8&     0.75&               45&                     91&                     $-$102.22\%\\ \hline
 9&     0.8&                121&                    186&                    $-$53.72\%\\ \hline
10&     0.8&                261&                    417&                    $-$59.77\%\\ \hline
11&     0.7&                444&                    364&                    $+$18.02\%\\ \hline
12&     0.65&               457&                    463&                    $-$1.31\%\\ \hline
13&     0.7&                448&                    582&                    $-$29.91\%\\ \hline
14&     0.65&               494&                    609&                    $-$23.28\%\\ \hline
15&     0.65&               598&                    513&                    $+$14.21\%\\ \hline
16&     0.65&               662&                    606&                    $+$8.46\%\\ \hline
18&     0.65&               911&                    688&                    $+$24.48\%\\ \hline
20&     0.55&               889&                    862&                    $+$3.04\%\\ \hline
22&     0.5&                1234&                   1211&                   $+$1.86\%\\ \hline
24&     0.4&                1209&                   1182&                   $+$2.23\%\\ \hline
26&     0.45&               1599&                   942&                    $+$41.09\%\\ \hline
32&     0.5&                2298&                   1995&                   $+$13.19\%\\ \hline
\end{tabular}
\label{table:firstsol}
\end{table}

\section{Conclusions and Further Study Remarks}
The main conclusion of our study was that in both single and multi-objective optimization of the N-Queen problems using our self-adaptive GA approach, our approach performs better than traditional GA even when optimized control parameters are used. This answers the question, why not use fixed mutation? Traditional GA with a fixed $M_{c}$ cannot adapt to the stage of search that the algorithm is in. At some times in the traversal of the problem landscape, it is desirable to converge on a local or global optimum. In other circumstances, the search must be widened. When only using mutation as a fixed background operation na\"{i}vely, there is no choice. Because we are using a self-adaptive approach, mutation can change and adapt based on the problem size, the characteristics of the problem landscape, problem difficulty, and time.

Exploring our variable mutation rate approach in other NP-Complete combinatorial and optimization problems such as the Traveling Salesman Problem or Constraint Satisfaction Problem may show that our approach is valid for a multitude of problems with different landscapes that have single global optima, or different optimal characteristics. We conjecture that this is likely since other adaptive mutation methodologies have yielded performance improvements in various problem domains.

Conducting a multivariate analysis and sensitivity analysis of tuning other parameters in conjunction with the variable adaptive mutation rate may yield further performance improvements. For example, variable population size based on the amount of inbreeding may yield different results. This conjecture is based on the fact that with higher mutation rates, survival fitness decreases, resulting in population shrinkage. Coupling the population size with the mutation rate and patterns of fitness in the GA population may yield a new avenue for future study.


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section
% NOTE: BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/

% can use a bibliography generated by BibTeX as a .bbl file
% standard IEEE bibliography style from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/supported/IEEEtran/testflow/bibtex
%\bibliographystyle{IEEEtran.bst}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)


\def\V{\rm vol.~}
\def\N{no.~}
\def\pp{pp.~}
\def\Pot{\it Proc. }
\def\IJCNN{\it IEEE World Congress On Computational Intelligence\rm }
\def\ACC{\it Beijing International Convention Center\rm }
\def\SMC{\it IEEE Trans. Systems\rm , \it Man\rm , and \it Cybernetics\rm } 

%TODO fill out

\begin{thebibliography}{20}

\bibitem{cit:1} K. Jong and W. Spears, ``Using Genetic Algorithms to Solve NP-complete Problems,"
        {\it Proceedings of the Third International Conference on Genetic Algorithms}, pp. 124-132, George Mason University, USA.

\bibitem{cit:2} K. Crawford, ``Solving the n-queens problem using genetic algorithms,"
        {\it Proceedings of the 1992 ACM/SIGAPP symposium on Applied computing: technological challenges of the 1990's}, SAC '92, pp. 1039-1047, New York, NY, USA 1992. ACM.

\bibitem{cit:3} A. Homaifar, J. Turner and S. Ali, ``The N-queens problem and genetic algorithms," 
        {\it Southeastcon '92, Proceedings., IEEE}, pp. 262-267, Birmingham, AL USA.

\bibitem{cit:4} P. Andrews, ``An investigation into mutation operators for particle swarm optimization,"
        {\it Evolutionary Computation, 2006. CEC 2006. IEEE Congress on}, pp. 1044-1051

\bibitem{cit:5} A. Tuson and P. Ross, ``Adapting operator settings in genetic algorithms,"
        {\it Evolutionary computation}, vol. 6, no. 2, pp. 161-184, The MIT Press, 1998.

\bibitem{cit:6} D. Wolpert and W. Macready, ``No free lunch theorems for optimization,"
        {\it Evolutionary Computation, IEEE Transactions on}, vol. 1, no. 1, pp. 67-82, IEEE, 1997.

\bibitem{cit:7} M. Srinivas and L. Patnaik, ``Adaptive probabilities of crossover and mutation in genetic algorithms,"
        {\it Systems, Man and Cybernetics, IEEE Transactions on}, vol. 24, no. 4, pp. 656-667, IEEE, 1994.

\bibitem{cit:8} M. Srinivas and L. Patnaik, ``Genetic algorithms: A survey,"
        {\it Computer}, vol. 27, no. 6 pp. 17--26, IEEE, 1994.

\bibitem{cit:9} D. Goldberg and J. Holland, ``Genetic algorithms and machine learning,"
        {\it Machine learning}, vol. 3, no. 2, pp. 95-99, Springer, 1988.

\bibitem{cit:10} D. Goldberg, ``Genetic and evolutionary algorithms come of age,"
        {\it Communications of the ACM}, vol. 37, no. 3, pp. 113-119, ACM, 1994.

\bibitem{cit:11} K. Jong, ``Adaptive system design: a genetic approach,"
        {\it Systems, Man and Cybernetics, IEEE Transactions on}, vol. 10, no. 10, pp. 566-574, IEEE, 1980.

\bibitem{cit:12} Z. Ye, Z. Li and M. Xie, ``Some improvements on adaptive genetic algorithms for reliability-related applications,"
        {\it Reliability Engineering \& System Safety}, vol. 95, no. 2, pp. 120-126, Elsevier, 2010.

\bibitem{cit:13} J. Grefenstette, ``Optimization of control parameters for genetic algorithms,"
        {\it Systems, Man and Cybernetics, IEEE Transactions on}, vol. 16, no. 1, pp. 122-128, IEEE, 1986.

\bibitem{cit:14} J. Hesser and R. M{\"a}nner, ``Towards an optimal mutation probability for genetic algorithms,"
        {\it Parallel Problem Solving from Nature}, vol. 496, pp. 23-32, Springer Berlin Heidelberg, 1991.
%Editors

\bibitem{cit:15} J. Coyne and R. Paton, ``Genetic algorithms and directed adaptation,"
        {\it IEEE Transactions on Circuits and Systems}, vol. 33, no. 5, pp. 533-541, 1986.
%Editors

\bibitem{cit:16} M. Negnevitsky,
        {\it Artificial Intelligence: A Guide To Intelligent Systems}, Pearson Education Limited, edition 2, 2005


\bibitem{cit:17} R. Clark, J. Stainer, H. Haynes, R. Buckner, JE. Mosier, AJ. Quinn and others,
        {\it Medical and genetic aspects of purebred dogs}, Veterinary Medicine Publishing Co., 690 South 4th Street, 1983.


\bibitem{cit:18} P. Mannucci and E. Tuddenham, ``The hemophilias—from royal genes to gene therapy,"
        {\it New England Journal of Medicine}, vol. 344, no. 23, pp. 1773-1779, Mass Medical Soc., 2001.

\bibitem{cit:19} D. Goldberg and K. Deb, ``A comparative analysis of selection schemes used in genetic algorithms,"
        {\it Urbana}, vol. 51, pp. 61801-2996, 1991.

\bibitem{cit:20} Masehian, Ellips and Akbaripour, Hossein and Mohabbati-Kalejahi, Nasrin, ``Landscape analysis and efficient metaheuristics for solving the n-queens problem,"
        {\it Computational Optimization and Applications}, vol. 56, pp. 735-764, 1991.


\bibitem{cit:21} C.S. Pearson and M.S. Pearson, ``A140450 The count of how many queens must be placed tentatively onto a board while seeking a first solution to the "N-Queens on an N x N chessboard" puzzle,"
        {\it The Online Encyclopedia of Integer Sequences}, Aug. 2008. [Online]. Available: http://oeis.org/A140450. [Accessed Jan. 10, 2014].

\end{thebibliography}

% that's all folks
\end{document}
