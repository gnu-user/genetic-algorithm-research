% This is "sig-alternate.tex" V2.0 May 2012
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}
\usepackage{epstopdf}
\usepackage{algorithm2e}
\usepackage{multirow}
\usepackage{hyperref}
%\usepackage{auto-pst-pdf}
\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{GECCO2014}{2014 Victoria, BC, Canada}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Enhancing the Performance of Genetic Algorithms in Combinatorial Optimization of Large and Difficult Problems}
\subtitle{Using Variable Adaptive Mutation Rates Controlled by 'Inbreeding'}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{4} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Daniel Smullen\titlenote{Corresponding author.}\\
       \affaddr{UOIT}\\
       \affaddr{2000 Simcoe St. N}\\
       \affaddr{Oshawa, ON, Canada}\\
       \email{daniel.smullen@uoit.net}
% 2nd. author
\alignauthor
Jonathan Gillett\\
       \affaddr{UOIT}\\
       \affaddr{2000 Simcoe St. N}\\
       \affaddr{Oshawa, ON, Canada}\\
       \email{jonathan.gillett@uoit.net}
% 3rd. author
\alignauthor
Joseph Heron\\
       \affaddr{UOIT}\\
       \affaddr{2000 Simcoe St. N}\\
       \affaddr{Oshawa, ON, Canada}\\
       \email{joseph.heron@uoit.net}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor Shahryar Rahnamayan\\
       \affaddr{UOIT}\\
       \affaddr{2000 Simcoe St. N}\\
       \affaddr{Oshawa, ON, Canada}\\
       \email{shahryar.rahnamayan@uoit.ca}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\additionalauthors{}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Blah blah blah, here is our abstract.
\end{abstract}

\keywords{Genetic Algorithms, Combinatorial Optimization, N Queens Problem, Variable Mutation}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% INTRODUCTION
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
Genetic algorithms serve an important role in various applications, but particularly useful areas are those where they can perform stochastic generation of solutions for combinatorial problems. One notable example of this is the N-Queens problem. One approach to solving the N-Queens problem using a genetic algorithm is to implement chromosomes which model the position of each queen on the chessboard. The permuted values stored in the chromosome represent the sequential row positions of each queen, encoded into binary values. Each column value is the index, since there can never be more than one queen per column. Thus, the column positions increase by one for each queen and the intersections (referred to as collisions) are calculated per row or on the diagonal to determine whether a solution has been found. As with any genetic algorithm, evaluating the fitness of the chromosomes per generation is required to determine if a usable solution has been generated. 

By tuning the parameters of the genetic algorithm, performance can increase or decrease based on the solution landscape of the problem encountered. We have found that by replacing a static mutation value with an adaptive value controlled by chromosome similarity, better performance can be achieved than using static values, particularly when there is no \emph{a priori} knowledge about the ideal static mutation rate. This is compounded when the solution landscape is large, such as in higher-order N-Queens problems.

\subsection{Background and Problem Domain}
Like many other complex optimization problems, the N-Queens problem becomes orders of magnitude more complex as the number of queens and the size of the chessboard increases. Finding all solutions is a simple but non-trivial problem. When two or more queens share a row or diagonal, a collision occurs for each pair of queens, meaning that the board state is not a solution.

The Eight-Queens problem is the classical version of the puzzle, and even with this configuration the problem is computationally expensive. There are {$64 \choose 8$} arrangements of the queens on a standard {$8\times{}8$} board. Exhaustive deterministic evaluation has shown that there are only 92 distinct solutions. Even including optimizations such as imposing a constraint to place only one queen to a single row, there are still {$8^8$} possible distinct arrangements. In higher-order versions of the problem, combinatorial explosion occurs. The Nine-Queens problem has 352 distinct solutions. The Ten-Queens problem has 724. Table \ref{table:numuniquesol} in section \ref{table:numuniquesol} shows the growth of the number of solutions. 

While the number of solutions is known for problems involving up to 26 queens, there is currently no known formula to determine the exact number of distinct solutions. That is to say, higher order N-Queens problems are currently intractable with existing methods. Deterministic methods for approaching these problems are largely useless, and the problem remains unsolved.

- (ADD CITATIONS!
  
% CITATIONS EXAMPLE WITH ALL CITATATIONS
- Cite me!\cite{crawford1992solving,homaifar1992e1,andrews2006investigation,tuson1998adapting, wolpert1997no,srinivas1994adaptive,goldberg1988genetic}

\subsubsection{The N-Queens Puzzle}
The natural question raised when approaching simple problems is why a deterministic or brute force strategy is not used. Unfortunately, these approaches cannot work within human time-frames except in smaller problem landscapes. The issue is that a direct linear traversal of the landscape does not yield fruitful results easily in the case of the N-Queens problem. This stems from the fact that the fitness of each sequential solution doesn't matter. The problem cannot be solved by producing a solution that has queens which will attack each other. Therefore, only solutions with the absolute maximum, 100\% fitness, are useful solutions. What is more, as the problem landscape increases in size, the number of distinct solutions does not increase proportionally. A full brute force traversal of the landscape would be required to find all the distinct solutions, which is increasingly expensive in higher order problems.

Other stochastic solutions are impractical with this type of problem. This is because finding solutions among the landscape of possible board states yields a tremendous amount of duplicate solutions. Some method is required to direct the random traversal of the landscape toward distinct solutions and away from those which have already been found. The problem with this statement, is that the nature of randomness cannot be constrained in this way - it will no longer be random. Therefore methods such as genetic algorithms become an attractive solution approach  because they represent a 'smarter' traversal of the problem landscape than what is offered by a linear brute force traversal, or a uniformly random traversal of the landscape. Less time is spent on areas of the landscape which are not likely to be solutions. This leads us toward the core motivation of our solution's behavior.

- (ADD CITATIONS!)

\subsubsection{Motivation}\label{motivation_section}
Modeling the randomness of the solution landscape as seen in the N-Queens problem is impossible with known mathematical methods. To produce a geometric solution landscape would require that the dependent axis of the coordinate plane maps each sequential value to a uniformly random value in the actual solution landscape. Conceptually this is very difficult to imagine, but the reason why this conceptual strategy is useful will become clearer. First, we will discuss why a new approach is necessary in comparison to traditional GA approaches.

There are several 'short-cuts' which are available when approaching the N-Queens problem because of the nature of the chess board. Since it is square, one solution in fact can be used to yield many other unique solutions using symmetry operations (reflection and rotation of the board). This means that up to 8 solutions can be generated by finding one distinct solution. However, symmetry operations cannot be used to find all distinct solutions because many symmetrical configurations of the board are equivalent. In the example of the Eight-Queens problem, there are 11 board configurations which yield 8 solutions, and 1 which yields only 4. The result is still 92 unique solutions, with the majority of them calculable through symmetry operations alone.

Using symmetry operations, our initial exploration into solving the N-Queens problem yielded solutions quickly, but not quickly enough to beat deterministic solution generation methods. This was especially apparent in lower order problems where the solution landscape is small. We began to explore biological definitions of genetics, and sought inspiration from the fact that nature has an apparent system for maintaining genetic variation within organisms. For example pure-bred dogs often tend to have significant health problems which directly result from inbreeding. Royal families historically used inbreeding to keep their line 'pure', which also resulted in genetic abnormalities. (CITE THIS)

These facts led us toward a theoretical approach to apply the negative effects of inbreeding towards genetic algorithms. Our approach would make the mutation rate variable based on chromosome similarity, suggesting the natural mutant products of inbreeding as a result of a too-similar biological chromosome. Our initial solution worked exceptionally well, providing all 92 solutions nearly instantaneously in comparison to our previous static mutation rate GA which required a few seconds. This motivated us to pursue the implications of our strategy further.

\subsection{Related Work}

Classic Genetic Algorithms (GA) have been used extensively as a means to optimize tasks [Genetic and evolutionary algorithms come of age][Genetic Algorithms: a survey][Using Genetic algorithms to solve np-complete problems]. A popular problem to benchmark Optimization algorithms, such as GA is to use the N-Queens problem [The N-Queens Problem and Genetic Algorithms][Solving the n-Queens Problem using Genetic Algorithms]. However as stated in [AUTHOR Solving the n-Queens Problem using Genetic Algorithms], the N-Queens problem is very different from most NP-Complete problems. This stems from the fitness evaluates to a binary value. This prevents a direction search since there is no feedback besides absolute correct or incorrect. 

One major concern with using GA is determining the best genetic operators, the probability of mutation and crossover. These operators values are defined prior to the execution and remain static for the entire execution in the classical GA. [AUTHOR Towards an Optimal Mutation Probability for Genetic Algorithms] attempt to define an algorithmically solution to provide suitable genetic operators [Towards an Optimal Mutation Probability for Genetic Algorithms]

Attempts to improve the selection of these genetic operations have been made over the last few decades. Since GA are inspired by real life, the adjustments tend to be based in adding more nature based augmentations to improve the performance of GA. One major example of this is Adaptive Genetic Algorithms (AGA) which generally, is an attempt to adjust the genetic operations actively to escape local optimum faster and reach maximums quicker. An typical example of AGA uses a defined measurement of the current 'performance' of the population by evaluating the population's fitness. Use of these AGAs requires less knowledge of the search space. For example the better the fitness the lower the mutation and alternatively the worse the fitness the higher the mutation [Genetic Algorithms and Directed Adaptation] [Adaptive probabilities of crossover and mutation in genetic algorithms]. 

More specifically, [AUTHOR Genetic Algorithms and Directed Adaptation] only changed the mutation rate between two values, a 'hypermutable' (high) rate, and normal (typical mutation) rate [Genetic Algorithms and Directed Adaptation]. Use of the fitness function of the population provides the indicator for switching between the two values. [AUTHOR Adaptive probabilities of crossover and mutation in genetic algorithms] provides a similar example however, where the genetic operator are not restricted to two values, rather they are calculated [Adaptive probabilities of crossover and mutation in genetic algorithms]. A bit of a different approach to AGA is described by [AUTHOR Adapting Operator Settings in Genetic Algorithms] which accounts for each member in the population to have its own defined genetic operators. The genetic operators will be adapted in the creation of the next generation [Adapting Operator Settings in Genetic Algorithms]

[AUTHORS Some improvements on adaptive genetic algorithms for reliability-related applications] gives a fundamental look at adaptive genetic algorithms by comparing two major, contradicting processes: mutation-first, and crossover-first. Mutation-first relies on a high mutation rate and a low crossover rate initially and over time it will progress to the opposite, a low mutation rate and a high crossover rate. Crossover-first is the exact opposite, with a low mutation and a high crossover rate initially and closer to the end of the execution a high mutation and a low crossover for the end. It was found that the mutation-first method out performed the crossover-first [Some improvements on adaptive genetic algorithms for reliability-related applications]. This can be attributed to the need to explore the search space early in the execution (through mutation) and to make slight adjustments (through crossover) later on [Some improvements on adaptive genetic algorithms for reliability-related applications]. An attempt is also made to provide a plausible method to the local optimum problem by introducing randomly generated individuals to the population to increase diversity [Some improvements on adaptive genetic algorithms for reliability-related applications].



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% APPROACH
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Our Solution Approach}\label{params}
Ordinary genetic algorithms use three parameters to govern their evaluation. The first is the population size. We have not adjusted this parameter in our experiments, and kept them at a fixed value of 64 chromosomes. Second is the chromosome crossover rate, which governs the likelihood and percentage of a chromosome to splice with another. This was also kept static, at a fixed rate of 70\%. The third parameter is mutation rate, which governs the likelihood that a chromosome will have a random gene modified. This is achieved using a bit-flipping operation on the selected gene's binary encoded values. To support the 'in-breeding' variant of the algorithm, we have selected to replace the fixed mutation rate parameter with a variable rate, governed by a separate parameter which was kept at a fixed value for the sake of experimentation. The separate parameter, chromosome similarity threshold, is expressed as a percentage. We have selected 15\% as an arbitrary threshold which seemed to work well during experimentation. Future studies into the nature of this parameter may yet yield improved results for specific circumstances. The offset by which the mutation rate is adjusted (based on the chromosome similarity parameter) is set at a fixed value of 1\%.

(cite paper justifying why we used these values, they are often recommended/used values, Genetic Algorithms by Goldberg)


\subsection{Applying Adaptive Variable Mutation Rates}
In order to apply our adaptive variable mutation rate, a two step process is required. For each generation of chromosomes, the population chromosome similarity must be evaluated. The similarity algorithm is detailed in a separate subsection.  

When the chromosome similarity is less than the specified threshold, the mutation rate must decrease. For the next generation, the mutation rate is decreased. If the chromosome similarity increases again, and it goes above the specified threshold, the mutation rate decreases. Due to the stochastic nature of the algorithm, wild variations in chromosome similarity may result regardless of the mutation rate. Since the crossover of the genes may be up to 70\%, the resultant permutations of the genome are likely to be similar unless some mutation occurs. The result of this adaptive change in mutation rate is that the chromosome similarity will approach an equilibrium close to the specified inbreeding threshold.

% This is essentially explaining the chromosome similarity algroithm since the concept of 
% applying variable mutation from the previous subsection can be easily explained in words 
% without a formal algorithm.
\subsubsection{Chromosome Similarity Algorithm}
Chromosome similarity is calculated using a greedy algorithm seen in Algorithm \ref{alg:similarity}. First, the chromosomes' genes are decoded into integer values by direct translation of their binary values in sequence to an integer. next, the array of chromosomes' integer representations is sorted. Our implementation uses the quick-sort algorithm for minimal computational overhead. This gives the algorithm its' characteristic asymptotic behavior, as the complexity of the actual sorting function itself is of higher complexity than the main similarity calculation algorithm. That is to say, the sorting function used runs on average in $O(n \log n)$ complexity, although it should be noted that in the theoretical worst case, quick-sort works in $O(n^2)$ which is highly unlikely. The main algorithm runs in $O(n)$ linear complexity.

\begin{algorithm}
  \SetKwProg{Fn}{Function}{}{end}\SetKwFunction{Similarity}{Similarity}%
  \SetKwData{Similar}{similar}\SetKwData{Value}{value}\SetKwData{Matched}{matched}\SetKwData{Length}{length}\SetKwArray{Sorted}{sorted}
  \SetKwFunction{Sort}{Sort}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetAlgoLined
  \DontPrintSemicolon
  
  \Fn{\Similarity{$chromosomes$}}{
  
  \Input{An array of $chromosomes$}
  \Output{Fraction of chromosomes that are similar}
  \BlankLine
  
  \Similar $\leftarrow$ 0\;
  \Matched $\leftarrow$ false\;
  \Length $\leftarrow$ length of $chromosomes$\;
  \BlankLine
  
  \tcp{Sort using an arbitrary sorting algorithm}
  \Sorted $\leftarrow$ \Sort{$chromosomes$}\;
  \BlankLine
  
  \For{$i \leftarrow 0$ \KwTo $\Length -1$}
  {
    \uIf{\Sorted{$i$} == \Sorted{$i + 1$}}
    {
      \Similar $\leftarrow$ \Similar + 1\;
      \Matched $\leftarrow$ true\;
    }
    \ElseIf{\Matched}
    {
      \Similar $\leftarrow$ \Similar + 1\;
      \Matched $\leftarrow$ false\;
    }
    \BlankLine
    
    \tcp{Case where the last item is a match}
    \If{\Matched and $\left(i + 1 == \Length - 1 \right)$}
    {
      \Similar $\leftarrow$ \Similar + 1\;
    }
  }
  \BlankLine
  \KwRet{\Similar / \Length}
  }
\caption{Chromosome similarity function}
\label{alg:similarity}
\end{algorithm}




% I thought it would be important to add a section on implementation
% this could be condensed, but I think it is very important to
% explain how we actually implemented and applied the GA process
\subsection{Implementation Specific Considerations}
In order to gain an appreciation for the specific implementation and how it might compare to alternatives, we will attempt to elaborate upon the special implementation considerations we made. Our experiments were performed on the same code as our development code, which was written in Java. Concurrent agile development was used as our main development methodology, and GitHub was used extensively for version management and simultaneous development of the code, documentation, and this report. 

The project source code is available at \url{http://www.github.com/gnu-user/}

% This is the design of the chromosome, which is important to the implementation details
\newpage
\subsubsection{Chromosome Design}

Chromosomes are designed with an optimization that allow the stochastic search space to be minimized significantly, mentioned originally in section \ref{motivation_section}. The result is that the dimensionality of the problem decreases. This is accomplished by encoding each gene as a row (or column) position on the chess board, and each single index in the array of values means there can only be one queen placed at each index. This allows for an extendable chromosome up to N. Figure \ref{fig:chromosome} shows this chromosome pictorially for a $7 \times 7$ chessboard. In the figure, the 4th, 5th and 6th rows are not shown, but are filled with a queen at the 4th, 5th and 6th column positions respectively in this chromosome. As a result, the encoded chromosome is represented by 7 Java Integer class values in sequence. To encode this into one mutable array, the integers are simply concatenated together. The array specified in Figure \ref{fig:chromosome} would thus be translated to $1274563$.

\begin{figure}[h]
\centering
\includegraphics[width=0.35\textwidth]{chromosome.png}
\vspace{-12pt}
\caption{Illustrating the chromosome data structure.}
\label{fig:chromosome}
\end{figure}


% The implementation detail of the fitness funciton including the algorithm
\subsubsection{Fitness Function}
Fitness is evaluated by determining the number of collisions between queens on the chessboard - in other words, when at least two queens can attack each other, a collision occurs for each queen. This means that in a board state where only one queen can attack another, two collisions result. Because it is impossible for there to be more than one queen per column given the data structure, only collisions across rows and diagonals must be found. The algorithm for determining the fitness of a given board state is given in Algorithm \ref{alg:fitness}, showing the mechanisms we used to find collisions across rows and diagonals. The fitness is calculated as $1 - \frac{1}{(1/N)}$, where the maximum fitness (a unique board solution) is $1$. The length of the chromosome corresponds to the number of queens and rows on the square chessboard, $N$.
 

\begin{algorithm}[t!]
  \SetKwProg{Fn}{Function}{}{end}\SetKwFunction{Fitness}{Fitness}%
  \SetKwData{Collisions}{collisions}\SetKwData{Length}{length}\SetKwArray{Chromosome}{$chromosome$}\SetKwData{Yi}{$y_i$}\SetKwData{Yj}{$y_j$}
  \SetKwFunction{Abs}{abs}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetAlgoLined
  \DontPrintSemicolon
  
  \Fn{\Fitness{$chromosome$}}
  {
    \Input{A single $chromosome$}
    \Output{A fitness value for the chromosome}
    \BlankLine
    
    \Collisions $\leftarrow$ 0\;
    \Length $\leftarrow$ length of the $chromosome$\;
    \BlankLine
    
    \For{$i \leftarrow 0$ \KwTo $\Length -1$}
    {
      \tcp{Check each gene against the current}
      $j \leftarrow \left( i + 1 \right) \mod{\Length}$\;
      \While{$j$ != $i$}
      {
        \Yi $\leftarrow \Chromosome{i}$\;
        \Yj $\leftarrow \Chromosome{j}$\;
        \BlankLine
        
        \tcp{Check for vertical collision}
        \If{\Yi == \Yj}
        {
          \Collisions $\leftarrow \Collisions + 1$\; 
        }
        \BlankLine
        
        \tcp{Check for diagonal collision}
        \If{\Abs{$\left(i - j \right)$ / $\left(\Yi - \Yj \right)$} == 1}
        {
          \Collisions $\leftarrow \Collisions + 1$\;
        }
        \BlankLine
        
        $j \leftarrow j + 1$\;
        $j \leftarrow j \mod{\Length}$\;
      }
    }
    \BlankLine

    \eIf{\Collisions == 0}
    {
      \KwRet{1}\;
    }
    {
      \KwRet{1 / \Collisions}\;
    }
  }
\caption{Fitness function}
\label{alg:fitness}
\end{algorithm}


% The selection method, we use roulette wheel, however the implementation details of how
% roulette wheel is implemented is important
\subsubsection{Selection Method}
As per traditional genetic algorithms, roulette wheel selection was used. This process works by filling the roulette wheel with fractional parts of a total. This is analogous to a probability distribution between zero and 1 - in our implementation the range will lie between 0 and the sum of all the fitness values of each chromosome in a generation.

Each chromosome is given a fraction of the roulette wheel, whose size is equal to the chromosome's fitness divided by the total fitness of all values. A random floating point value is generated between zero and the sum of the total fitness values. This floating point value will lie within one of the intervals representing one of the chromosomes. Whichever interval it falls in is the selected chromosome. The order in which the chromosomes' intervals are placed doesn't matter, as each 'spin' of the roulette wheel is random - the floating point number generated is created based on a uniformly random distribution.

% The operations, these are pretty standard but we need to cite why we chose 70% and 30%
% we used these because they were recommended (e.g. from AI lectures) but need textbooks
% or papers to suggest why we used them
\subsubsection{Chromosome Operations}
As mentioned in section \ref{params}, the crossover rate is set at a fixed 70\%. This means that 30\% of the time, the genes in the child chromosomes will be an exact clone of the parents. the remaining times, a random crossover occurs. This is done the traditional way by selecting a random index as the bounds for the portion of the gene to cross over. All indexes to the right of this index (including the index value itself) are swapped. Between the two parents, the first parent's values to the right of the index, and the second parent's values to the left of the index are combined to create one child (and the other way around for the second child).

Background mutation, naturally, affects chromosomes randomly after the crossover or cloning process takes place. Each chromosome has a percentage chance of being affected by mutation, and this likelihood changes every generation due to the adaptive variable mutation rate. When a chromosome is selected for mutation, one of the genes in that chromosome is selected randomly. It is then set to a random, valid value. Valid values are between 0 and N corresponding to each row on the chessboard.

% How we evaluate chromosomes in the population and determine distinct solutions
% and apply rotate and reflection to find additional solutions
% The use of terminology here is important DISTINCT implies that the particular
% arrangment of queens is different from another rotation/reflection of the same original
% solution. UNIQUE would consider all reflections/rotations as ONE "unique" solution
\newpage
\subsubsection{Chromosome Evaluation}
Each generation, there is a likelihood that some of the chromosomes in the current population are valid solutions - any of the current generation's chromosomes with a fitness of 1 is some sort of solution. When a solution is found, it must be compared to the list of previously found solutions to ensure it is not a duplicate. Due to the stochastic nature of the algorithm, it is a strong possibility that many solutions can be found which are duplicates of previous solutions. To add to this fact is that the symmetry operations applied to each solution found may further increase the likelihood that the new population's solutions that have already been found. Duplicate solutions are discarded without having symmetry operations applied as they would be identical to symmetric configurations of existing found solutions.

Upon saving any newly found solutions, the new generation replaces the previous generation and the genetic algorithm process cycle continues again.

% I would instead call this methodology and make testing/validation/etc. subsections
%\subsubsection{Testing and Validation}
\subsection{Experimental Methodology}
Experiments were conducted using the high performance computing facilities provided by SHARCNET. Testing of our process was performed by using two different configurations for each N value of the N-Queens problem. Tests were performed for N = 8 up to 16, and then increasing increments of 2 from 18 to 20, 22, 24, 26 and 32. A fixed number of generations was allowed for each trial in order to ensure that the tests had a finite running time. For all runs, 10 million generations were allowed, except for N = 32, where 50 million generations were allowed given the increased complexity of the problem.

The first configuration used static mutation rates set at m = 1\%, 5\%, 10\%, and every further increment of 5\% up to 100\%. These were used as a control. The second configuration used the adaptive variable mutation rate, and the results were compared. 

For N = 8 through 16, 30 tests were performed at each static mutation rate ($21 \times 30 = 630$ tests total), and then 30 runs were performed using variable mutation rates. 

For N = 18 through 26, 15 tests were performed under both configurations. For N = 32, 10 tests were performed. The decrease in the number of tests performed for higher values of N was largely due to the running time required to generate meaningful results. SHARCNET allowed us to execute a maximum of 256 jobs at one time, with 7 days CPU time each. The N = 32 Queens problem required this limit to be fully utilized in order to give results. Given the intractable size of the higher-order N-Queens problems, an unsustainable amount of time and CPU power would be required to finish these problems within our time constraints and were not tested.

Further, given the volume of data generated by the number of trials, statistical attributes of the results collected (such as mean population fitness and chromosome similarity) were calculated using the mean of every 1000 generations in order to observe the central tendency. A total of roughly 6 gigabytes of data was generated as a result of this process, which was manageable given our allocation of storage space on SHARCNET. The requirements for collecting the data at every generation would have been 1000 times that volume (approximately 6 terabytes) which far exceeded our allocation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% RESULTS
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Results and Analysis}
It became clear very quickly when we plotted the results of our tests that the variable mutation method was not suitable in its current configuration for the simpler N-Queens problems. In fact, we found that given sufficient knowledge about the problem landscape for the lower-order problems, the right static mutation value would likely beat variable mutation every time. The key point that this makes is that for ordinary non-benchmark usage of genetic algorithms, it is useless to use a static mutation rate value unless you already know the correct value for the problem. This generally speaks to the point that having an adaptive mutation rate approach will likely find this value. The smaller N-Queens problems are too small to merit the usage of a stochastic approach regardless, as deterministic methods can yield solutions quickly, and with a guarantee of success.

\subsection{'Traversing' the Problem Landscape}
Moving into more complex and larger problems is where the adaptive mutation approach becomes increasingly successful. Our reasoning is that this may have something to do with the similarity threshold that was chosen, and further tuning of this parameter may yield better results for larger or smaller problems. We have created a conceptual model for these findings which may yet be validated in future studies:

Approaching the solution landscape for the N-Queens problem means mapping a random non-deterministic traversal of the solution space to a linear axis. Each sequential value on this axis corresponds literally to each integer sequence of solutions encoded in the chromosomes. A linear traversal of this landscape implies a uniformly random traversal of the stochastic solutions. This, in contrast to the actual linear solution space yielded by increasing the values of the integer encoded chromosome, has very few similarities. There is no way to plot a random traversal except by noting that as time approaches infinity, all solutions will have been traversed and the full contour of the landscape will be visible. This could just as easily be yielded by a deterministic linear traversal - the genetic algorithms make the traversal 'smarter' by looking for values which have better fitness, approaching peaks in the landscape. The mutation operator prevents the current position in the traversal from being stuck in a local optimum. It provides an extra impulse to shift position further towards what a potential solution, and away from previously traversed areas of the landscape.

Given this knowledge, assuming a linear traversal of this random axis is possible in one given test, we can evaluate the characteristics of each genetic algorithm configuration and map them to this conceptual model. The starting point on the plot is a random location even among the linearized random axes. From there, the next location is likely to be within a circle surrounding this area. We have come to refer to this circle as the 'step size', and we believe there is some relationship between the step size and the fixed mutation rate. That is to say, the fixed mutation rate governs the maximum distance from the current position in the traversal, and the furthest step away. What this means for a solution landscape like that of the N-Queens problem is that all solutions which are close to the intersections of these possible steps are easier to find because there is a greater probability of landing directly on them. Solutions which are clustered very close together on this random landscape, however, will likely be stepped around for several generations before convergence o the actual solutions occurs.

The variable mutation rate's adaptive nature allows for this fixed step size problem to be surmounted because it introduces the ability to vary the step size when convergence upon a solution occurs. Our reasoning is that if the static mutation rates have a fixed step size, the variable mutation rate does not, and will vary the step size so as to maintain the chromosome similarity. Further, this decreases the likelihood of overshooting a solution and having to step back around again, because the variability of the mutation rate allows for smaller or larger steps when needed.

In general, this conceptual model is an interesting thought experiment, but will require extensive further study to validate it's correctness. Meanwhile, the empirical evidence presented in our plotted results shows the validity of our adaptive mutation rate methodology in general.

\subsection{Plotted Results and Observations}


- cite specific results and why we think they are important, what is the significance
  of them and how they support our results/hypothesis that in the case of N Queens
  var. mutation is better than fixed.

There appears to be a relationship 

- cite the result showing the best fixed mutation vs. the variable mutation
  for each N-queens problem, try and use both the figure and the table, the table
  has some additional interesting information which cannot be conveyed in the
  image alone.

An interesting result was observed when viewing the box plots showing the range of chromosome similarity value for each static mutation rate. We found that whenever the similarity has the greatest inter-quartile range, the corresponding static mutation rate performed best. This contributed heavily to the step size concept we believe is exhibited by the system. We also found that as the problem landscape grows larger in higher order N-Queens problems, the inter-quartile range decreases in size. There is a possibility that the convergence of these values may occur in even higher order problems, which suggests that there may be a pattern to the convergence which can be approximated and leveraged for predicting optimal static mutation rates. Again, since this requires exhaustive experimentation in order to definitively find the optimal static mutation rate for a given problem, this further supports the notion that a variable mutation rate is a more practical approach.

- Try and incorporate one of the scatter plots as well that show very interesting
  results and see if you can use it to compare/contrast the results of the 
  following plots
  
    - variable mutation rate scatter plot
    - variable mutation rate similarity scatter plot
    - best fixed mutation rate similarity scatter plot

\subsection{Why Not Fixed Mutation?}
Results aside, fixed mutation gives a distinct advantage over traditional genetic algorithms because of the optimization of a specific parameter. By using a variable mutation rate, changing that parameter with a separate simpler one, better results can be gleaned while knowing less about the problem landscape. Our results show that our variable adaptive mutation scheme can perform better than fixed static mutation values for large problems. As the problem becomes too large and unmanageable for traditional methods, our methodology can still produce useful results. Our results show that even having knowledge about the best static mutation value to use \emph{a priori} still does not yield results as good as those generated from the adaptive variable mutation rate.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% CONCLUSIONS
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and Further Study}

- Further research into adjusting the inbreeding threshold, for the purpose
  of the research a constant inbreeding threshold of 15\% was used, however
  further research could be done in testing different thresholds.

- Comparing the results of variable mutation with fixed mutation using other
  types of combinatorial/optimization problems such as TSP, constraint
  satisfaction problem (CSP), etc.

- Variable population size based on the amount of inbreeding (if you have
  a lot of inbreeding in nature the organisms will have higher mutatation
  rate and deformities, the population will shrink)

- Having the mutation operator affect more than one gene if it goes > 100\%? 

\begin{flushleft}\end{flushleft}


%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.

- Shahryar

- SHARCNET


%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%

%APPENDICES are optional
%\balancecolumns
\appendix
%Appendix A
\section{Results}
The rules about hierarchical headings discussed above for
the body of the article are different in the appendices.
In the \textbf{appendix} environment, the command
\textbf{section} is used to
indicate the start of each Appendix, with alphabetic order
designation (i.e. the first is A, the second B, etc.) and
a title (if you include one).  So, if you need
hierarchical structure
\textit{within} an Appendix, start with \textbf{subsection} as the
highest level. Here is an outline of the body of this
document in Appendix-appropriate form:

\subsection{Tables}
\begin{table}[!h]
\centering
\caption{Number of unique solutions to the N-Queens Problem}
\begin{tabular}{|l|l|} \hline
N & Distinct Solutions      \\ \hline
1  & 1                      \\
2  & 0                      \\
3  & 0                      \\
4  & 2                      \\
5  & 10                     \\
6  & 4                      \\
7  & 40                     \\
8  & 92                     \\
9  & 352                    \\
10 & 724                    \\
11 & 2680                   \\
12 & 14,200                 \\
13 & 73,712                 \\
14 & 365,596                \\
15 & 2,279,184              \\
16 & 14,772,512             \\
17 & 95,815,104             \\
18 & 666,090,624            \\
19 & 4,968,057,848          \\
20 & 39,029,188,884         \\
21 & 314,666,222,712        \\
22 & 2,691,008,701,644      \\
23 & 24,233,937,684,440     \\
24 & 227,514,171,973,736    \\
25 & 2,207,893,435,808,352  \\
26 & 22,317,699,616,364,044 \\
27 & Unknown				\\
\dots & Unknown				\\
\hline\end{tabular}
\label{table:numuniquesol}
\end{table}


\begin{table*}
\centering
\caption{Best Solution Comparison Between Fixed and Variable Mutation Rates}
\begin{tabular}{|l|l|l|l|l|l|l|} \hline
Queens&               Mutation Rate&  Unique Solutions&   N&      Min Generations&    Mean Generations&   Max Generations\\ \hline
\multirow{2}{*}{8}&   0.95&           92&                 30&     1,793&              4,746&              10,815\\
&                     variable&       92&                 30&     51,23&              15,293&             42,002\\ \hline
\multirow{2}{*}{9}&   0.95&           352&                30&     48,811&             144,456&            372,281\\
&                     variable&       352&                30&     229,242&            1,246,215&          3,038,980\\ \hline
\multirow{2}{*}{10}&  0.9&            724&                30&     188,372&            408,402&            771,208\\
&                     variable&       724&                30&     531,588&            1,629,893&          6,195,099\\ \hline
\multirow{2}{*}{11}&  0.85&           2,680&              30&     2,400,188&          3,799,795&          5,933,213\\
&                     variable&       2,680&              5&      6,900,512&          7,909,269&          9,449,545\\ \hline
\multirow{2}{*}{12}&  0.85&           13,690&             1&      9,890,455&          9,890,455&          9,890,455\\
&                     variable&       11,986&             1&      9,973,787&          9,973,787&          9,973,787\\ \hline
\multirow{2}{*}{13}&  0.8&            32,128&             1&      9,998,058&          9,998,058&          9,998,058\\
&                     variable&       26,308&             1&      9,978,215&          9,978,215&          9,978,215\\ \hline
\multirow{2}{*}{14}&  0.8&            41,520&             1&      9,996,747&          9,996,747&          9,996,747\\
&                     variable&       29,520&             1&      9,999,583&          9,999,583&          9,999,583\\ \hline
\multirow{2}{*}{15}&  0.8&            30,356&             1&      9,982,638&          9,982,638&          9,982,638\\
&                     variable&       30,324&             1&      9,996,584&          9,996,584&          9,996,584\\ \hline
\multirow{2}{*}{16}&  0.8&            15,016&             1&      9,987,788&          9,987,788&          9,987,788\\
&                     variable&       30,132&             1&      9,992,266&          9,992,266&          9,992,266\\ \hline
\multirow{2}{*}{18}&  0.75&           16,392&             1&      9,997,986&          9,997,986&          9,997,986\\
&                     variable&       27,120&             1&      9,998,858&          9,998,858&          9,998,858\\ \hline
\multirow{2}{*}{20}&  0.75&           7,872&              1&      9,972,915&          9,972,915&          9,972,915\\
&                     variable&       25,608&             1&      9,931,631&          9,931,631&          9,931,631\\ \hline
\multirow{2}{*}{22}&  0.7&            6,008&              1&      9,959,712&          9,959,712&          9,959,712\\
&                     variable&       25,376&             1&      9,991,089&          9,991,089&          9,991,089\\ \hline
\multirow{2}{*}{24}&  0.7&            6,440&              1&      9,929,626&          9,929,626&          9,929,626\\
&                     variable&       24,560&             1&      9,998,508&          9,998,508&          9,998,508\\ \hline
\multirow{2}{*}{26}&  0.7&            6,280&              1&      9,969,840&          9,969,840&          9,969,840\\
&                     variable&       23,008&             1&      9,983,128&          9,983,128&          9,983,128\\ \hline
\multirow{2}{*}{32}&  0.65&           15,216&             1&      49,732,320&         49,732,320&         49,732,320\\
&                     variable&       104,080&            1&      49,996,701&         49,996,701&         49,996,701\\
\hline\end{tabular}
\label{table:numuniquesol}
\end{table*}


\subsection{Figures}

- Additional figures can go here

\subsection{Source Code}

- Could link to github and possibly the github wiki, or explanation
  of the R analysis source code.

\subsection{Raw Data}

- Link to the dropbox URL containing the actual data from SHARCNET used for the research


\end{document}
